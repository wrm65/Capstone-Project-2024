## Project Report

### This project is a culmination of the six months programme on Machine Learning and Artificial Intelligence.
- In <code>Module 2: Introduction to Machine Learning</code>, we learned about the ten steps of a typical machine learning project.

- <details>
  <summary>In completing this final project, these are the steps that were applied:</summary>

   <p>
    <ol type="1">
     <li><b>Define the purpose of the ML project</b>
     <ul>
       <li>Understanding the objective: Predicting Ofsted school grading based on various features.</li>
       <li>Identifying the target variable and potential predictors.</li>
       <li>Defining success criteria for model evaluation.</li>
     </ul>
     </li>
     <li><b>Obtain the data set for the analysis</b>
     <ul>
       <li>Gathering relevant data sources related to schools and Ofsted ratings.</li>
       <li>Ensuring data quality and completeness.</li>
       <li>Handling missing values appropriately.</li>
     </ul>
     </li>
     <li><b>Explore, clean & preprocess the data</b>
     <ul>
       <li>Exploring and visualising the data to gain insights into distributions.</li>
       <li>Preprocessing data, including encoding categorical variables, and handling imbalanced classes.</li>
       <li>The over-sampling technique <code>SMOTE</code> (Synthetic Minority Oversampling Technique) was used to address the imbalanced classes.</li>
     </ul>
     </li>
     <li><b>Dimension reduction & feature engineering</b>
     <ul>
       <li>Selecting relevant features that could impact Ofsted ratings.</li>
       <li>Creating new features or transforming existing ones to improve model performance.</li>
     </ul>
     </li>
     <li><b>Determine the ML task at hand</b>
     <ul>
       <li>Evaluating different algorithms suitable for the prediction task, such as regression, decision trees, or ensemble methods.</li>
       <li>I included two additional models which we did not cover during the programme - <code>Gradient Boosting Classifier</code> and <code>Multilayer Perceptron Classifier</code>.</li>
     </ul>
     </li>
     <li><b>Partition the data (if supervised ML)</b>
     <ul>
       <li>Splitting data into training, validation, and test sets.</li>
     </ul>
     </li>
     <li><b>Choose the ML technique(s)</b>
     <ul>
       <li>Training selected models using the training data.</li>
     </ul>
     </li>
     <li><b>Use the ML technique(s)</b>
     <ul>
       <li>Tuning hyperparameters to optimise model performance.</li>
       <li>Considering the trade-offs between model complexity, interpretability, and performance.</li>
     </ul>
     </li>
     <li><b>Interpret the results</b>
     <ul>
       <li>Assessing model performance using evaluation metrics relevant to the problem, such as accuracy, precision, recall, or F1 score.</li>
       <li>Comparing models based on their performance on the testing set.</li>
       <li>Understanding the factors driving predictions through model interpretation techniques such as feature importance analysis or decision tree.</li>
     </ul>
     </li>
     <li><b>Deploy the ML technique (optional)</b>
     <ul>
       <li>not required</li>
     </ul>
     </li>
    </ol>
   </p>

</details>
 
### Furthermore, this project also allowed me to enhance my proficiency in developing machine learning models using Python.

- <details>
  <summary>Key lessons are:</summary>

   <p>
    <ol type="1">
     <li><b>Data Preprocessing and Balancing Techniques</b>
     <ul>
       <li>Class imbalance is a common challenge in classification tasks, and implementing data preprocessing techniques such as oversampling, undersampling, or generating synthetic samples (e.g., SMOTE) helps balance class distributions.</li>
       <li>Utilise libraries such as <code>imbalanced-learn</code> to implement resampling techniques and handle class imbalance effectively.</li>
     </ul>
     </li>
     <li><b>Model Selection and Evaluation</b>
     <ul>
       <li>It's crucial to select appropriate evaluation metrics that account for class imbalance, such as F1 score, precision, and recall, in addition to accuracy.</li>
       <li>Use libraries like <code>scikit-learn</code> to evaluate model performance using various metrics and cross-validation techniques to ensure robustness.</li>
     </ul>
     </li>
     <li><b>Hyperparameter Tuning</b>
     <ul>
       <li>Hyperparameter tuning plays a significant role in optimising model performance, especially in addressing class imbalance.</li>
       <li>Utilise techniques such as grid search or randomized search with cross-validation to find the best combination of hyperparameters for each model.</li>
     </ul>
     </li>
     <li><b>Ensemble Methods</b>
     <ul>
       <li>Ensemble methods, such as Random Forest and Gradient Boosting, are effective in handling class imbalance and improving predictive performance.</li>
       <li>Experiment with ensemble methods and analyse their impact on model performance compared to individual classifiers.</li>
     </ul>
     </li>
     <li><b>Feature Engineering and Selection</b>
     <ul>
       <li>Feature engineering and selection can help improve model performance and reduce overfitting, especially in the presence of class imbalance.</li>
     </ul>
     </li>
     <li><b>Interpreting Model Results</b>
     <ul>
       <li>Understanding and interpreting model results, including confusion matrices and feature importance, are crucial for identifying areas of improvement and gaining insights into model behavior.</li>
       <li>Visualise and analyse model results using libraries like <code>matplotlib</code> and <code>seaborn</code>, and interpret feature importance using built-in functionalities of machine learning libraries.</li>
     </ul>
     </li>
    </ol>
   </p>

  </details>

### Contact

- Winston Menzies
- winston.menzies@grammology.education
<div align="left">
  <img src="https://github.com/wrm65/Capstone-Project-2024/blob/main/images/email_logo-01_190x65.png">
</div>
